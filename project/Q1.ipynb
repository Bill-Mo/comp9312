{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Order of Presenting Works\n",
        "\n",
        "For Q1, I have tried five methods to solve it. In order to let the code run from top to down, I will present my last version first, which performed best and put my four other versions of code at the bottom. Altough it performed best, it cannot always find the shortest path."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scXgqZZR_G3L"
      },
      "source": [
        "## Idea and Definitions\n",
        "My idea came from this paper: Fast Exact Shortest-Path Distance Queries on Large Networks by Pruned Landmark Labeling, which I will refer as `[1]` below. The idea is based on two-hop cover and two-hop labels. Basically, a two-hop cover has a center node and two node sets, one containing nodes that are reachable to center and the shortest distance to it, and one containing nodes and shortest distance that are reachable from center. Two-hop labels are a table of the set of two-hop covers that contains all the nodes reachability and shortest distance. We check two-hop labels table to respond shortest distance query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![q1.1](./q1.1.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example\n",
        "In this eample, (a) is our graph, where the weight of edges are all 1. \n",
        "(b) and (c) are two two-hop covers, which is consisted by three node layers. The top layer represents nodes that can reach the center node, which is the only node on the middle layer. The bottom layer contains nodes that can be accessed from the center node. The distance between layers are all shortest distance. \n",
        "(d) is the two-hop labels, which froms by two-hop covers. `L(ni)` stands for in and out labels of node `ni`. Two-hop labels are consisted by an in edge and out edge sets where edges are represented by another end of the node and the shortest distance between the node and label node. \n",
        "\n",
        "For instance, to find a path from `n3` to `n15`, we check out edges from `n3`, which is the second set in `L(n3)`, and in edges to `n15`, which is the first set in `L(15)`. If we find `n15` in out edges of `n3` or `n3` in in edges of `n15`, then we find the shorest path between them, because two-hop cover only stores the shortest path. In this case, we find `<n15: 2>` in `L(n3)`, which means the shortest path from `n3` to `n15` is 2. Otherwise, the overlapping nodes are potential shortest paths passing through them. We need to add distance from source node to overlapping nodes and distance from overlapping nodes to destionation nodes and get the minimum distance. for example, if we want to find the shortest distance between `n0` and `n7`, we find that `n8` and `n15` are both out edge of `n0` and in edge of `n7`. We calculate the shortest path from `n0` to `n7` passing `n8` and `n15` seperately. 2+2 < 3+2, thus the shortest distance from `n0` to `n7` is 4 passing thourgh `n8`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Code\n",
        "This section is simply importing some modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "from math import inf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Algorithm\n",
        "Our goal is to construct a two-hop labels. To achieve this, we do graph traversal from each node to form two-hop covers. A naive way is to do Dijkstra algorithm to find the shortest paths from each center nodes, which is one of my methods and I will mention more details below. However, it has time complexity `O(V^3)`, which is obviously inefficient and impractical. \n",
        "\n",
        "`[1]` proposed a pruned BFS. The strategy is as follows: Initially, we set distance between all nodes to infinity. While doing BFS for each center node `v`, when visiting a node `u`, we query two-hop labels the distance from `v` to `u`. If the query distance is bigger than distance from current BFS, we add edge `(v, u)` into two-hop labels and append `u` into queue for traversal. Otherwise, we start to visit the next node in the queue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![q1.2](./q1.2.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Two-Hop Cover\n",
        "Below is the initialization of my two-hop cover class. It takes graph G, center node and two-hop labels as arguments. `labels` will be updated thrgouhout finding two-hop covers. The structure of `labels` will be introduced in `Shortest Distance Section`. Notice that two-hop cover need to do two graph traversal, one for outgoing edges and one for incoming edges.\n",
        "\n",
        "### Pruned BFS\n",
        "This section will briefly explain my code. In general, my code follows the Algorithm 1 above. The argument `direction` is either `\"in\"` or `\"out\"`. When direction is `\"out\"`, it does outgoing traversal, which is the same as normal traversal. When direction is `\"in\"`, it traverses through reverse edges.\n",
        "\n",
        "In the pruning precess, I add lines to compare original neighbor's distance to current distance and update it, which is different from `[1]`. This is because `[1]` assume all edges have same weights, thus no needs to update for different edge weights.\n",
        "\n",
        "The function `query_with_label()` is the same as the query function for doing final query except it use labels from argument and it reverse the label direction if direction is `\"in\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TwoHopCover():\n",
        "    def __init__(self, G, center, labels):\n",
        "        self.G = G\n",
        "        self.center = center\n",
        "        self.prunedBFS(labels, 'out')\n",
        "        self.prunedBFS(labels, 'in')\n",
        "            \n",
        "    def prunedBFS(self, labels, direction):\n",
        "        # Some initialization\n",
        "        G = self.G\n",
        "        src = self.center\n",
        "        dist = {}\n",
        "        q = deque()\n",
        "        q.append(src)\n",
        "        for v in G.vertex_dict:\n",
        "            dist[v] = inf\n",
        "        dist[src] = 0\n",
        "\n",
        "        # Pruned BFS\n",
        "        while len(q) != 0:\n",
        "            u = q.popleft()\n",
        "            # Pruning\n",
        "            if self.query_with_label(src, u, labels, direction) > dist[u]:\n",
        "                labels[src][direction][u] = dist[u]\n",
        "\n",
        "                # Use reverse edges if direction is \"in\"\n",
        "                if direction == 'out':\n",
        "                    edges = G.adj_list_out[G.vertex_dict[u]]\n",
        "                else:\n",
        "                    edges = G.adj_list_in[G.vertex_dict[u]]\n",
        "\n",
        "                for edge in edges:\n",
        "                    v = edge[0]\n",
        "                    v_dist = edge[1]\n",
        "                    if dist[v] == inf:\n",
        "                        q.append(v)\n",
        "                    \n",
        "                    # Different from the paper: update weight to neighbor if current path have shorter distance\n",
        "                    if dist[v] > dist[u] + v_dist:\n",
        "                        dist[v] = dist[u] + v_dist\n",
        "        return\n",
        "                \n",
        "    # Query function used in pruned BFS\n",
        "    def query_with_label(self, source_vertex, target_vertex, labels, direction):\n",
        "        reverse_direction = 'in' if direction == 'out' else 'out'\n",
        "        out_label = {out_v for out_v in labels[source_vertex][direction]}\n",
        "        in_label = {in_v for in_v in labels[target_vertex][reverse_direction]}\n",
        "\n",
        "        # If target node is in source node's label or vise versa, immediatly return the shortest distance\n",
        "        if source_vertex in in_label:\n",
        "            return labels[target_vertex][reverse_direction][source_vertex]\n",
        "        if target_vertex in out_label:\n",
        "            return labels[source_vertex][direction][target_vertex]\n",
        "        \n",
        "        # Else we need to find the middle node.\n",
        "        dist = inf\n",
        "        for mid_v in out_label & in_label:\n",
        "            curr_dist = labels[source_vertex][direction][mid_v] + labels[target_vertex][reverse_direction][mid_v]\n",
        "            if curr_dist < dist:\n",
        "                dist = curr_dist\n",
        "        return dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![q1.3](./q1.3.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Shortest Distance\n",
        "This section I will introduce how I preprocess the graph by two-hop cover class above.\n",
        "`labels` is a dictionary which contains vertices as keys matching the two-hop cover as the keys as center nodes. The two-hop covers is a dictionary that have two keys, `\"in\"` and `\"out\"` which seperately store in and out distance to reachable nodes. for example, there is edges from `A` to `C` with weight `2` and `A` to `D` with weight `6`. labels would be like this: \n",
        "`{\n",
        "    \"A\": {\n",
        "        \"in\": {}, \n",
        "        \"out\": {\"C\": 2, \"D\": 6}\n",
        "    }\n",
        "    \"C\": {\n",
        "        \"in\": {\"A\": 2}\n",
        "        \"out\": {}\n",
        "    }\n",
        "    \"D\": {\n",
        "        \"in\": {\"A\": 6}\n",
        "        \"out\": {}\n",
        "    }\n",
        "}`\n",
        "### Preprocess\n",
        "The preprocess function basically follows Algorithm 2 above. The difference is the order of nodes to calculate two-hop cover. Though Algorithm 2 choose node randomly, `[1]` mentioned the order of center node is also a crucial factor. The less nodes we add into two-hop labels, the less redundent our table is. \n",
        "\n",
        "Thus it is better to start from nodes that its two-hop cover covers the most short edges, and end at nodes that its cover covers the most redundent edges. In my code, I process nodes that have higher degree first, becaus they are more likely to contain short edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ShortestDistance(object):\n",
        "    def __init__(self, G):\n",
        "        self.G = G\n",
        "        vertices = list(G.vertex_dict.keys())\n",
        "        self.labels = {v: {'in': {}, 'out': {}}  for v in vertices}\n",
        "        self.preprocess(G, self.labels)\n",
        "            \n",
        "    def preprocess(self, G, labels):\n",
        "        labels = self.labels\n",
        "        degrees = self.get_degrees(G)\n",
        "        \n",
        "        # While there is node haven't been processed\n",
        "        while len(degrees) != 0:\n",
        "            curr_degree = -1\n",
        "            curr_v = ''\n",
        "\n",
        "            # Find node with highest degree\n",
        "            for v in degrees:\n",
        "                next_degree = degrees[v]\n",
        "                if next_degree >= curr_degree:\n",
        "                    curr_degree = next_degree\n",
        "                    curr_v = v\n",
        "            if curr_v == '':\n",
        "                break\n",
        "            degrees.pop(curr_v)\n",
        "            TwoHopCover(G, curr_v, labels)\n",
        "        return \n",
        "\n",
        "    # Similar to query_with_label above\n",
        "    def query(self, source_vertex, target_vertex):\n",
        "        labels = self.labels\n",
        "        out_label = {out_v for out_v in labels[source_vertex]['out']}\n",
        "        in_label = {in_v for in_v in labels[target_vertex]['in']}\n",
        "\n",
        "        if source_vertex in in_label:\n",
        "            return labels[target_vertex]['in'][source_vertex]\n",
        "        if target_vertex in out_label:\n",
        "            return labels[source_vertex]['out'][target_vertex]\n",
        "\n",
        "        dist = inf\n",
        "        for mid_v in out_label & in_label:\n",
        "            curr_dist = labels[source_vertex]['out'][mid_v] + labels[target_vertex]['in'][mid_v]\n",
        "            if curr_dist < dist:\n",
        "                dist = curr_dist\n",
        "        return dist\n",
        "\n",
        "    # Given graph G, return a dictionary that vertex is key and degree of vertex is value\n",
        "    def get_degrees(self, G):\n",
        "        vertices = list(G.vertex_dict.keys())\n",
        "        d = {v: (len(G.adj_list_in[G.vertex_dict[v]]) + len(G.adj_list_out[G.vertex_dict[v]])) for v in vertices}\n",
        "        return d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Time and Space Complexity\n",
        "\n",
        "The time and space complexity for pruned BFS is `O(m+n)`. In preprocessing, we do `n` times pruned BFS, so the time complexity for preprocessing is `O(n(m+n))`. However, in practice, we rarely reach to the worst case, especially for pruned BFS, because as we store more labels, the less later nodes can traverse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5QO20WBK4cC"
      },
      "source": [
        "## 2. Graph Data Structure\n",
        "Below is the data stucture of the input graph `G` in the `ShortestDistance` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dm0J3MV3J_f1"
      },
      "outputs": [],
      "source": [
        "############################################################################\n",
        "# Do not edit this code cell.\n",
        "############################################################################\n",
        "\n",
        "class DirectedWeightedGraph(object):\n",
        "  def __init__(self, edge_list):\n",
        "      self.vertex_dict = {}\n",
        "      self.adj_list_in = []\n",
        "      self.adj_list_out = []\n",
        "      self.vertex_num = 0\n",
        "      for [src, dst, weight] in edge_list:\n",
        "          self.add_edge(src, dst, weight)\n",
        "\n",
        "  def add_vertex(self, name):\n",
        "      id = self.vertex_num\n",
        "      self.vertex_dict[name] = id\n",
        "      self.vertex_num += 1\n",
        "      self.adj_list_in.append(list())\n",
        "      self.adj_list_out.append(list())\n",
        "\n",
        "  def add_edge(self, vertex1, vertex2, weight):\n",
        "      if vertex1 not in self.vertex_dict.keys():\n",
        "          self.add_vertex(vertex1)\n",
        "      if vertex2 not in self.vertex_dict.keys():\n",
        "          self.add_vertex(vertex2)\n",
        "      self.adj_list_out[self.vertex_dict[vertex1]].append([vertex2, weight])\n",
        "      self.adj_list_in[self.vertex_dict[vertex2]].append([vertex1, weight])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pndqCjIHPgR4"
      },
      "source": [
        "## 3. How to test your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUkHfISNJVQy"
      },
      "source": [
        "### 3.1 Download the sample dataset.\n",
        "\n",
        "Running the following command will create a folder COMP9312_datasets containing files about three datasets. **Cora** (2k vertices) is a real citation graph with an synthetic random weight for each edge. **map_BJ_part** (4k vertices) is a real road network for a small area of Beijing, and **map_NY_part** (7k vertices) is a real road network for a small area of New York. Each dataset has three files. For each dataset, ***.graph** includes all graph edges. ***.query** includes a set of shortest distance queries for testing. ***.answer** includes the answer for each query computed by us in the ***.query** file for your reference.\n",
        "\n",
        "If the dataset has already exists, there would be an error like \"*destination path 'COMP9312_datasets' already exists*\".\n",
        "\n",
        "**Note**: We will use different query datasets to test the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTFnVaSoCYSu",
        "outputId": "5b9c08ac-6b13-48a4-9a9e-c655cbdbe92e"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/guaiyoui/COMP9312_datasets.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYFEswmCBQyR"
      },
      "source": [
        "### 3.2 The main function\n",
        "\n",
        "Our test procedure first loads the graph dataset and the query dataset. Then it calls the `ShortestDistance` class to preprocess the graph. After that, it will run each query and test their efficiency and correctness. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyrG7Mx5Krmu",
        "outputId": "9892b08f-5b53-42b8-d1c2-d6391d908c95"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print('\\n##### Loading the dataset...')\n",
        "    # edge_list = np.loadtxt('./COMP9312_datasets/cora.graph', dtype=int)\n",
        "    # query_list = np.loadtxt('./COMP9312_datasets/cora.query', dtype=int)\n",
        "    edge_list = np.loadtxt('./COMP9312_datasets/map_BJ_part.graph', dtype=int)\n",
        "    query_list = np.loadtxt('./COMP9312_datasets/map_BJ_part.query', dtype=int)\n",
        "    # edge_list = np.loadtxt('./COMP9312_datasets/map_NY_part.graph', dtype=int)\n",
        "    # query_list = np.loadtxt('./COMP9312_datasets/map_NY_part.query', dtype=int)\n",
        "    G = DirectedWeightedGraph(edge_list)\n",
        "\n",
        "    print('\\n##### Start to preprocessing...')\n",
        "    start_preprocessing = time.time()\n",
        "    SD = ShortestDistance(G)\n",
        "    end_preprocessing = time.time()\n",
        "    print(\"preprocessing time: {}\".format(end_preprocessing-start_preprocessing))\n",
        "\n",
        "    print('\\n##### Test on the query ...')\n",
        "    start_query = time.time()\n",
        "    for i in range(query_list.shape[0]):\n",
        "      distance = SD.query(query_list[i][0], query_list[i][1])\n",
        "      print(\"the distance between {} and {} is: {}\".format(query_list[i][0], query_list[i][1], distance))\n",
        "    end_query = time.time()\n",
        "    print(\"average  query time: {}\".format((end_query-start_query)/query_list.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Appendix\n",
        "\n",
        "In this section, I will introduce my other thoughts in regard to Q1. All my methods did not change graph structure, so I will not repeatedly provide graph class in my code. I did not change `DirectedWeightedGraph`. To test them, simply uncomment and run them. Some of my code is incomplete and some are inefficient. In order not to cause any errors from them, I will make them comment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 1\n",
        "\n",
        "The idea came from this paper: On-line Exact Shortest Distance Query Processing, which will be referred to as `[2]` below. The method is two-hop cover based, which is similar to the above method. Apart from that, `[2]` exploit strongly connected components, or simply SCCs, and DAG components and partition graphs to speed up the preprocessing. Besides, it proposed a method to reduce the redundancy of two-hop cover."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Algorithm\n",
        "\n",
        "The Algorithm shown below, called DAPar, contains two main parts. First (lines 1 to 7), collapse SCCs into DAGs by removing some nodes. Next (lines 8 to 15), the graph will be partitioned into small subgraphs by removing some nodes until we obtain two hop covers for the whole graph. Two-hop covers are computed when removing nodes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![q1.4](./q1.4.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The figure below shows the whole preprocessing process. Figure (a), (b) and (c) match the first step. Figure (d) and (e) match the second step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![q1.5](./q1.5.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step One: Collapse SCC to DAG\n",
        "\n",
        "In this section, I will discuss how SCCs collapse to DAGs.\n",
        "\n",
        "The first thing that should be done is to break the cycles. The optimal solution is to remove the minimum number of nodes to break all the cycles. To avoid high consumption of computation power, `[2]` did not break all cycles at once. Instead, it used an early stop strategy. That is, first, get a fixed amount of cycles. Second, find the minimum number of nodes that break current cycles. Then, repeat the first and second steps.\n",
        "\n",
        "After collapsing SCCs, we need to get the two-hop covers for removed nodes. Different from `[1]`, it forms two-hop covers according to Algorithm 2 below. The detailed method to compute two-hop covers in `[2]` is Dijkstra Algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![q1.6](./q1.6.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step Two: Top-down Partitioning\n",
        "\n",
        "To partition the graph, we find a set of so-called node-separator `Vw` and remove them from the graph. `[2]` introduced two strategies, the fixed strategy for dense graphs and the flexible strategy for sparse graphs. Here, I will only talk about the fixed strategy.\n",
        "\n",
        "For the fixed strategy, previous studies have proved that with the same space cost, a two-hop cover covers more paths when the cardinality of ancestor nodes and descendent nodes are more similar. That is, balanced 2-hop clusters are preferred. Therefore, the strategy found a node-separator from the middle of the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Time and Space Complexity\n",
        "\n",
        "In terms of time complexity, step one takes `O(m(m+n))` times to collapse SCCs. However, the early stop strategy can speed up a lot. In step two, it takes `O(m)` to partition all nodes. It takes `O(n^2)` time to compute two-hop covers by running Dijkstra. In all, time complexity is `O(m^2+n^2+mn)`. The space complexity for two-hop cover is `O(n^2)`, if every cover stores all other nodes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code (incomplete)\n",
        "\n",
        "Below is my code for this method. Due to time limitations and the complexity of the algorithm, I did not finish it. The function `get_strongly_connected_components()` is able to return all SCCs in the graph. However, I stopped at finding cycles in SCCs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "from collections import namedtuple\n",
        "import copy\n",
        "\n",
        "path = namedtuple('path', ['src', 'dest', 'distance'])\n",
        "early_stop = 30\n",
        "\n",
        "class ShortestDistance(object):\n",
        "    def __init__(self, G):\n",
        "        self.G = G\n",
        "        self.preprocess(G)\n",
        "\n",
        "    def preprocess(self):\n",
        "        G = collapse_G(G)\n",
        "        split_G(G)\n",
        "\n",
        "    def query(self, source_vertex, target_vertex):\n",
        "        shortest_distance = 0\n",
        "        return shortest_distance\n",
        "\n",
        "def collapse_G(G):\n",
        "    SCCs = get_strongly_connected_components()\n",
        "    for SCC in SCCs:\n",
        "        cycles = getCycles(G, SCC)\n",
        "        v_hat = getDAG(cycles)\n",
        "        for v in v_hat:\n",
        "            add_two_hop_cover(v)\n",
        "    G = remove_v(v_hat)\n",
        "    return G\n",
        "\n",
        "def split_G(G, v_sep)-> None:\n",
        "    v_sep = find_separator()\n",
        "    G_top, G_bot = separate_G(G, v_sep)\n",
        "    for v in v_sep:\n",
        "        add_two_hop_cover(v)\n",
        "\n",
        "    if is_small(G_top):\n",
        "        for v in G_top:\n",
        "            add_two_hop_cover(v)\n",
        "    else:\n",
        "        split_G(G_top)\n",
        "\n",
        "    if is_small(G_bot):\n",
        "        for v in G_bot:\n",
        "            add_two_hop_cover(v)\n",
        "    else:\n",
        "        split_G(G_bot)\n",
        "\n",
        "def get_strongly_connected_components(G) ->list:\n",
        "    SCCs = []\n",
        "    visited = set()\n",
        "    stack = []\n",
        "    vertices = list(G.vertex_dict.keys())\n",
        "    for v in vertices: \n",
        "        if v not in visited:\n",
        "            DFS(G, [], v, visited, stack)\n",
        "    reverse = reverse_G(G)\n",
        "    visited = set()\n",
        "    while stack:\n",
        "        v = stack.pop()\n",
        "        if v not in visited:\n",
        "            component = DFS(reverse, [], v, visited, [])\n",
        "            SCCs.append(component)\n",
        "    return SCCs\n",
        "\n",
        "def getCycles(G, cycles):\n",
        "    \n",
        "def getDAG(cycles: list):\n",
        "    current_cycle = cycles\n",
        "    v_hat = set()\n",
        "    if len(cycles) > early_stop:\n",
        "        current_cycle = cycles[:early_stop]\n",
        "        next_cycle = cycles[early_stop:]\n",
        "        v_hat += getDAG(next_cycle)\n",
        "    \n",
        "    for vertices in cycles:\n",
        "        v_total += set(vertices)\n",
        "    v_appear_count = {}\n",
        "    for v in v_total:\n",
        "        for c in cycles\n",
        "\n",
        "def add_two_hop_cover(v):\n",
        "    pass\n",
        "def remove_v(v_hat): \n",
        "    pass\n",
        "def find_separator():\n",
        "    pass\n",
        "def separate_G(v_sep):\n",
        "    pass\n",
        "def is_small(G):\n",
        "    pass\n",
        "\n",
        "def DFS(G, traversal, vertex, visited, stack):\n",
        "    visited.add(vertex)\n",
        "    traversal.append(vertex)\n",
        "    neighbors = G.adj_list_out[G.vertex_dict[vertex]]\n",
        "    for out_edge in neighbors:\n",
        "        v = out_edge[0]\n",
        "        if v not in visited:\n",
        "            DFS(G, traversal, v, visited, stack)\n",
        "    stack.append(vertex)\n",
        "    return traversal\n",
        "\n",
        "def reverse_G(G):\n",
        "    r_G = copy.deepcopy(G)\n",
        "    temp = copy.deepcopy(r_G.adj_list_in)\n",
        "    r_G.adj_list_in = r_G.adj_list_out\n",
        "    r_G.adj_list_out = temp\n",
        "    return r_G\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 2\n",
        "\n",
        "The idea came from the lecture Path and Reachability. Inspired by the two-hop cover method in the lecture, I tried to implement it to find the shortest distance. My two-hop cover only considered the neighbor nodes, it did a recursive DFS when querying. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Time and Space Complexity\n",
        "\n",
        "The preprocessing space complexity for two-hop cover is `O(n^2)`. The time complexity for that is `O(n^2)`. The query time complexity is `O(m)`. In practice, the preprocessing speed is fast. But the query time is not acceptable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code (inefficient)\n",
        "\n",
        "The code for this method is completed, but the query time is quite long for big graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "from math import inf\n",
        "import copy\n",
        "\n",
        "class ShortestDistance(object):\n",
        "    def __init__(self, G):\n",
        "        self.G = G\n",
        "        self.labels_in, self.labels_out = self.preprocess(G)\n",
        "\n",
        "\n",
        "    def preprocess(self, G: DirectedWeightedGraph):\n",
        "        labels_in = []\n",
        "        labels_out = []\n",
        "        for v in range(G.vertex_num):\n",
        "            labels_in.append([]) \n",
        "            labels_out.append([]) \n",
        "\n",
        "        degree_pairs = self.get_graph_degree(G)\n",
        "        highest_degree = self.get_highest_degree(degree_pairs)\n",
        "        while highest_degree >= 0:\n",
        "            for d_pair in degree_pairs:\n",
        "                if highest_degree == d_pair[1]:\n",
        "                    curr_v = d_pair[0]\n",
        "                    d_pair[1] = -1\n",
        "                    break\n",
        "            for in_edge in G.adj_list_in[G.vertex_dict[curr_v]]:\n",
        "                in_v = in_edge[0]\n",
        "                in_dist = in_edge[1]\n",
        "\n",
        "                (labels_out[G.vertex_dict[in_v]]).append([curr_v, in_dist])\n",
        "                for out_label in labels_out[G.vertex_dict[in_v]]:\n",
        "                    mid_v = out_label[0]\n",
        "                    for in_label in labels_in[G.vertex_dict[curr_v]]:\n",
        "                        potential_mid_v = in_label[0]\n",
        "                        if mid_v == potential_mid_v:\n",
        "                            if out_label[1] + in_label[1] > in_dist:\n",
        "                                labels_out[G.vertex_dict[in_v]].remove(out_label)\n",
        "                                labels_in[G.vertex_dict[curr_v]].remove(in_label)\n",
        "                            elif out_label[1] + in_label[1] < in_dist:\n",
        "                                labels_out[G.vertex_dict[in_v]].remove([curr_v, in_dist])\n",
        "\n",
        "\n",
        "\n",
        "            for out_edge in G.adj_list_out[G.vertex_dict[curr_v]]:\n",
        "                out_v = out_edge[0]\n",
        "                out_dist = out_edge[1]\n",
        "                \n",
        "                labels_in[G.vertex_dict[out_v]].append([curr_v, out_dist])\n",
        "                for in_label in labels_in[G.vertex_dict[out_v]]:\n",
        "                    mid_v = in_label[0]\n",
        "                    for out_label in labels_out[G.vertex_dict[curr_v]]:\n",
        "                        potential_mid_v = out_label[0]\n",
        "                        if mid_v == potential_mid_v:\n",
        "                            if in_label[1] + out_label[1] > out_dist:\n",
        "                                labels_in[G.vertex_dict[out_v]].remove(in_label)\n",
        "                                labels_out[G.vertex_dict[curr_v]].remove(out_label)\n",
        "                            elif in_label[1] + out_label[1] < out_dist:\n",
        "                                labels_in[G.vertex_dict[out_v]].remove([curr_v, out_dist])\n",
        "            \n",
        "            highest_degree = self.get_highest_degree(degree_pairs)\n",
        "\n",
        "        return (labels_in, labels_out)\n",
        "\n",
        "    def query(self, source_vertex, target_vertex):\n",
        "        vertices = list(self.G.vertex_dict.keys())\n",
        "        return self.recQuery(source_vertex, target_vertex, 0, vertices)\n",
        "    \n",
        "    def recQuery(self, src, dest, dist, unvisited):\n",
        "        if len(unvisited) == 0:\n",
        "            return inf\n",
        "\n",
        "        G = self.G\n",
        "        labels_in = self.labels_in\n",
        "        labels_out = self.labels_out\n",
        "\n",
        "        for out_edge in labels_out[G.vertex_dict[src]]:\n",
        "            out_v = out_edge[0]\n",
        "            out_dist = out_edge[1]\n",
        "            if out_v == dest:\n",
        "                dist += out_dist\n",
        "                return dist\n",
        "                \n",
        "        for in_edge in labels_in[G.vertex_dict[dest]]:\n",
        "            in_v = in_edge[0]\n",
        "            in_dist = in_edge[1]\n",
        "            if in_v == src:\n",
        "                dist += in_dist\n",
        "                return dist\n",
        "        \n",
        "        curr_dist = inf\n",
        "        for out_edge in labels_out[G.vertex_dict[src]]:\n",
        "            out_v = out_edge[0]\n",
        "            out_dist = out_edge[1]\n",
        "            try:\n",
        "                unvisited.remove(out_v)\n",
        "                curr_dist = min(self.recQuery(out_v, dest, dist, copy.copy(unvisited)) + out_dist, curr_dist)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        for in_edge in labels_in[G.vertex_dict[dest]]:\n",
        "            in_v = in_edge[0]\n",
        "            in_dist = in_edge[1]\n",
        "            try:\n",
        "                unvisited.remove(in_v)\n",
        "                curr_dist =  min(self.recQuery(src, in_v, dist, copy.copy(unvisited)) + in_dist, curr_dist)\n",
        "            except:\n",
        "                pass\n",
        "        \n",
        "        return curr_dist\n",
        "        \n",
        "\n",
        "    def get_graph_degree(self, G: DirectedWeightedGraph):\n",
        "        degrees = []\n",
        "        vertices = list(G.vertex_dict.keys())\n",
        "        for v in vertices:\n",
        "            d = len(G.adj_list_in[G.vertex_dict[v]]) + len(G.adj_list_out[G.vertex_dict[v]])\n",
        "            d_pair = [v, d]\n",
        "            degrees.append(d_pair)\n",
        "        return degrees\n",
        "\n",
        "    def get_highest_degree(self, degree_pairs: list):\n",
        "        degrees = []\n",
        "        for d_pair in degree_pairs:\n",
        "            degrees.append(d_pair[1])\n",
        "        return max(degrees)\n",
        "        '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 3\n",
        "\n",
        "The idea came from this paper: Reachability and distance query via 2-hop labels, which will be referred to as `[3]`. It is also based on a two-hop cover. The problem it resolved is to find an optimal two-hop cover set. The strategy is before all nodes are covered, evaluate every two-hop cover by a ratio shown below and pick the best one. Add the cover to two-hop labels. In this way, the two-hop labels are close to optimal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![q1.7](./q1.7.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, w is the center node. C_in and C_out are the set of nodes that have an edge goes into and out w. S(C_in, w, C_out) represent the two-hop cover. T' means the residual edges that haven't been covered. |C_in| and |C_out| are numbers of nodes in sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Time and Space Complexity\n",
        "\n",
        "Although it can obtain a nearly optimal two-hop label table, the preprocessing space complexity is `O(n^2)` for two-hop covers, and `O(m)` for T'. In terms of time complexity, when preprocessing, every round we need to spend `O(m^2)` time to get the intersection of cover and `T`, then calculate the ratio for each two-hop cover one by one, which is `O(m^2n)` in all. The space complexity for labels is `O(m)`. In practice, the preprocessing time is quite large due to Dijkstra for every node and calculation ratio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code (Inefficient)\n",
        "\n",
        "The code is able to work, but the preprocessing time is quite long and impractical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "from itertools import permutations\n",
        "from math import inf\n",
        "import copy\n",
        "\n",
        "class TwoHopCover():\n",
        "    def __init__(self, G, center) -> None:\n",
        "        self.center = center\n",
        "        self.desc = self.dijkstra(G, center, 'out')\n",
        "        self.ancs = self.dijkstra(G, center, 'in')\n",
        "        \n",
        "    def cover(self):\n",
        "        return [self.ancs, self.desc]\n",
        "\n",
        "    def dijkstra(self, G: DirectedWeightedGraph, src, direction='out'):\n",
        "        dist = {}\n",
        "        prev = {}\n",
        "        q = list(G.vertex_dict.keys())\n",
        "        for v in G.vertex_dict:\n",
        "            dist[v] = inf\n",
        "            prev[v] = ''\n",
        "        dist[src] = 0\n",
        "        while len(q) != 0:\n",
        "            u = self.get_u(q, dist)\n",
        "            if dist[u] == inf:\n",
        "                break\n",
        "            q.remove(u)\n",
        "            if direction == 'out':\n",
        "                edges = G.adj_list_out[G.vertex_dict[u]]\n",
        "            else:\n",
        "                edges = G.adj_list_in[G.vertex_dict[u]]\n",
        "\n",
        "            for edge in edges:\n",
        "                v = edge[0]\n",
        "                v_dist = edge[1]\n",
        "                if dist[v] > dist[u] + v_dist:\n",
        "                    dist[v] = dist[u] + v_dist\n",
        "                    prev[v] = u\n",
        "        for v in list(G.vertex_dict.keys()):\n",
        "            if dist[v] == inf:\n",
        "                dist.pop(v)\n",
        "        dist.pop(src)\n",
        "        return dist\n",
        "                \n",
        "    def get_u(self, q: list, dist: dict) ->str:\n",
        "        nearest_v = q[0]\n",
        "        nearest_dist = dist[q[0]]\n",
        "        for v in q:\n",
        "            if dist[v] < nearest_dist:\n",
        "                nearest_v = v\n",
        "                nearest_dist = dist[v]\n",
        "        return nearest_v\n",
        "    \n",
        "    def cover_weight(self):\n",
        "        return len(self.ancs) + len(self.desc)\n",
        "    \n",
        "    def intersect(self, vertices):\n",
        "        non_covered_path = list(permutations(vertices, 2))\n",
        "        num_total = len(non_covered_path)\n",
        "        self.do_intersect(non_covered_path)\n",
        "        num_left = len(non_covered_path)\n",
        "        return num_total - num_left\n",
        "        \n",
        "    def do_intersect(self, non_covered_path):\n",
        "        for in_v in self.ancs:\n",
        "            ancs_path = (in_v, self.center)\n",
        "            if ancs_path in non_covered_path:\n",
        "                non_covered_path.remove(ancs_path)\n",
        "        for out_v in self.desc:\n",
        "            desc_path = (self.center, out_v)\n",
        "            if desc_path in non_covered_path:\n",
        "                non_covered_path.remove(desc_path)\n",
        "            \n",
        "    \n",
        "\n",
        "class ShortestDistance(object):\n",
        "    def __init__(self, G):\n",
        "        self.G = G\n",
        "        vertices = list(G.vertex_dict.keys())\n",
        "        self.labels = {v: {'in': {}, 'out': {}}  for v in vertices}\n",
        "        self.preprocess(G)\n",
        "\n",
        "\n",
        "    def preprocess(self, G: DirectedWeightedGraph):\n",
        "        vertices = list(G.vertex_dict.keys())\n",
        "        stored = set()\n",
        "        non_covered_path = list(permutations(vertices, 2))\n",
        "        cover_list = {v: TwoHopCover(G, v) for v in vertices}\n",
        "        curr_ratio = 0\n",
        "        curr_v = ''\n",
        "        while len(non_covered_path) != 0:\n",
        "            for v in cover_list:\n",
        "                next_ratio = cover_list[v].intersect(vertices) / cover_list[v].cover_weight()\n",
        "                if next_ratio >= curr_ratio and v not in stored:\n",
        "                    curr_ratio = next_ratio\n",
        "                    curr_v = v\n",
        "            \n",
        "            self.store_labels(cover_list[curr_v])\n",
        "            stored.add(curr_v)\n",
        "            prev_non_covered_path = copy.copy(non_covered_path)\n",
        "            cover_list[curr_v].do_intersect(non_covered_path)\n",
        "            if prev_non_covered_path == non_covered_path:\n",
        "                break\n",
        "        return \n",
        "\n",
        "    def query(self, source_vertex, target_vertex):\n",
        "        labels = self.labels\n",
        "        out_label = {out_v for out_v in labels[source_vertex]['out']}\n",
        "        in_label = {in_v for in_v in labels[target_vertex]['in']}\n",
        "\n",
        "        if source_vertex in in_label:\n",
        "            return labels[target_vertex]['in'][source_vertex]\n",
        "        if target_vertex in out_label:\n",
        "            return labels[source_vertex]['out'][target_vertex]\n",
        "\n",
        "        dist = inf\n",
        "        for mid_v in out_label & in_label:\n",
        "            curr_dist = labels[source_vertex]['out'][mid_v] + labels[target_vertex]['in'][mid_v]\n",
        "            if curr_dist < dist:\n",
        "                dist = curr_dist\n",
        "        return dist\n",
        "    \n",
        "    def store_labels(self, cover: TwoHopCover):\n",
        "        v = cover.center\n",
        "        labels = self.labels\n",
        "        for in_v in cover.ancs:\n",
        "            labels[in_v]['out'][v] = cover.ancs[in_v]\n",
        "        for out_v in cover.desc:\n",
        "            labels[out_v]['in'][v] = cover.desc[out_v]\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mathod 4\n",
        "\n",
        "This method simply implemented two-hop cover with no optimization. For the order of nodes to preprocess, I simply choose degree. Starting from the node with the highest degree, it compute two-hop cover by Dijkstra algorithm and store labels into the table. then it find the node with second high degree and repeat the process, until no new edge is stored in a round or all nodes have been processed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Time and Space Complexity\n",
        "\n",
        "As above mentioned, it takes `O(n^3)` time `O(n^2)` space to compute `n` two-hop covers. The preprocessing process does at most `n` rounds to remove at most `n` edges in each round. Thus the time complexity is `O(n^3)` in all. In practice, the process of computing two-hop cover is quite time-consuming, though it gives the correct shortest distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code (Inefficient)\n",
        "\n",
        "The code is completed and faster than mathod 2 and 3. However, it is still unacceptable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "from math import inf\n",
        "import copy\n",
        "\n",
        "class TwoHopCover():\n",
        "    def __init__(self, G, center) -> None:\n",
        "        self.center = center\n",
        "        self.max_edge = round(get_num_edges(G))\n",
        "        self.desc = self.dijkstra(G, center, 'out')\n",
        "        self.ancs = self.dijkstra(G, center, 'in')\n",
        "        \n",
        "    def cover(self):\n",
        "        return [self.ancs, self.desc]\n",
        "\n",
        "    def dijkstra(self, G: DirectedWeightedGraph, src, direction='out'):\n",
        "        dist = {}\n",
        "        edge_count = 0\n",
        "        q = list(G.vertex_dict.keys())\n",
        "        for v in G.vertex_dict:\n",
        "            dist[v] = inf\n",
        "        dist[src] = 0\n",
        "        while len(q) != 0 and edge_count < self.max_edge:\n",
        "            edge_count += 1\n",
        "            u = self.get_u(q, dist)\n",
        "            if dist[u] == inf:\n",
        "                break\n",
        "            q.remove(u)\n",
        "            if direction == 'out':\n",
        "                edges = G.adj_list_out[G.vertex_dict[u]]\n",
        "            else:\n",
        "                edges = G.adj_list_in[G.vertex_dict[u]]\n",
        "\n",
        "            for edge in edges:\n",
        "                v = edge[0]\n",
        "                v_dist = edge[1]\n",
        "                if dist[v] > dist[u] + v_dist:\n",
        "                    dist[v] = dist[u] + v_dist\n",
        "        for v in list(G.vertex_dict.keys()):\n",
        "            if dist[v] == inf:\n",
        "                dist.pop(v)\n",
        "        dist.pop(src)\n",
        "        return dist\n",
        "                \n",
        "    def get_u(self, q: list, dist: dict) ->str:\n",
        "        nearest_v = q[0]\n",
        "        nearest_dist = dist[q[0]]\n",
        "        for v in q:\n",
        "            if dist[v] < nearest_dist:\n",
        "                nearest_v = v\n",
        "                nearest_dist = dist[v]\n",
        "        return nearest_v\n",
        "    \n",
        "        \n",
        "    def do_intersect(self, uncovered_path):\n",
        "        count = 0\n",
        "        center = self.center\n",
        "        for in_v in self.ancs:\n",
        "            try: \n",
        "                uncovered_path[in_v].remove(center)\n",
        "                count += 1\n",
        "            except:\n",
        "                pass\n",
        "                \n",
        "        for out_v in self.desc:\n",
        "            try:\n",
        "                uncovered_path[center].remove(out_v)\n",
        "                count += 1\n",
        "            except:\n",
        "                pass\n",
        "        return count\n",
        "            \n",
        "    \n",
        "\n",
        "class ShortestDistance(object):\n",
        "    def __init__(self, G):\n",
        "        self.G = G\n",
        "        vertices = list(G.vertex_dict.keys())\n",
        "        self.labels = {v: {'in': {}, 'out': {}}  for v in vertices}\n",
        "        self.min_removed_edge = 0\n",
        "        self.preprocess(G)\n",
        "\n",
        "\n",
        "\n",
        "    def preprocess(self, G: DirectedWeightedGraph):\n",
        "        vertices = list(G.vertex_dict.keys())\n",
        "        degrees = self.get_degrees(G)\n",
        "        uncovered_path = {v: copy.copy(vertices) for v in vertices}\n",
        "        for v in vertices: \n",
        "            uncovered_path[v].remove(v) \n",
        "        rounds = 0\n",
        "        num_total_removed_edges = 0\n",
        "        print('removed edge number: {}'.format(num_total_removed_edges))\n",
        "        while self.get_num_path(uncovered_path) >= 0:\n",
        "            rounds += 1\n",
        "            print('rounds: {}'.format(rounds))\n",
        "            curr_degree = 0\n",
        "            curr_v = ''\n",
        "            for v in degrees:\n",
        "                next_degree = degrees[v]\n",
        "                if next_degree >= curr_degree:\n",
        "                    curr_degree = next_degree\n",
        "                    curr_v = v\n",
        "                if curr_v == '':\n",
        "                    break\n",
        "            print('found curr_v: {}'.format(curr_v))\n",
        "            degrees.pop(curr_v)\n",
        "            curr_cover = TwoHopCover(G, curr_v)\n",
        "            self.store_labels(curr_cover)\n",
        "            num_remove_edges = curr_cover.do_intersect(uncovered_path)\n",
        "            num_total_removed_edges += num_remove_edges\n",
        "            if num_remove_edges <= self.min_removed_edge:\n",
        "                print('stop. current edges: {}'.format(num_total_removed_edges))\n",
        "                break\n",
        "            print('reomve {} edges. current edges: {}'.format(num_remove_edges, num_total_removed_edges))\n",
        "        return \n",
        "\n",
        "    def query(self, source_vertex, target_vertex):\n",
        "        labels = self.labels\n",
        "        out_label = {out_v for out_v in labels[source_vertex]['out']}\n",
        "        in_label = {in_v for in_v in labels[target_vertex]['in']}\n",
        "\n",
        "        if source_vertex in in_label:\n",
        "            return labels[target_vertex]['in'][source_vertex]\n",
        "        if target_vertex in out_label:\n",
        "            return labels[source_vertex]['out'][target_vertex]\n",
        "        dist = inf\n",
        "        for mid_v in out_label & in_label:\n",
        "            curr_dist = labels[source_vertex]['out'][mid_v] + labels[target_vertex]['in'][mid_v]\n",
        "            if curr_dist < dist:\n",
        "                dist = curr_dist\n",
        "        return dist\n",
        "    \n",
        "    def get_num_path(self, uncovered_path):\n",
        "        count = 0\n",
        "        for v in uncovered_path:\n",
        "            count += len(uncovered_path[v])\n",
        "        return count\n",
        "\n",
        "    def store_labels(self, cover: TwoHopCover):\n",
        "        v = cover.center\n",
        "        labels = self.labels\n",
        "        labels[v]['in'][v] = 0\n",
        "        labels[v]['out'][v] = 0\n",
        "        in_label = {in_v for in_v in labels[v]['in']}\n",
        "        for in_v in cover.ancs:\n",
        "            out_label = {out_v for out_v in labels[in_v]['out']}\n",
        "            if not (in_label & out_label):\n",
        "                labels[in_v]['out'][v] = cover.ancs[in_v]\n",
        "            else:\n",
        "                for mid_v in (in_label & out_label):\n",
        "                    if labels[in_v]['out'][mid_v] + labels[v]['in'][mid_v] > cover.ancs[in_v]:\n",
        "                        labels[in_v]['out'][v] = cover.ancs[in_v]\n",
        "\n",
        "        out_label = {out_v for out_v in labels[v]['out']}\n",
        "        for out_v in cover.desc:\n",
        "            in_label = {in_v for in_v in labels[out_v]['in']}\n",
        "            if not (in_label & out_label):\n",
        "                labels[out_v]['in'][v] = cover.desc[out_v]\n",
        "            else:\n",
        "                for mid_v in (in_label & out_label):\n",
        "                    if labels[v]['out'][mid_v] + labels[out_v]['in'][mid_v] > cover.desc[out_v]:\n",
        "                        labels[out_v]['in'][v] = cover.desc[out_v]\n",
        "    \n",
        "    def get_degrees(self, G: DirectedWeightedGraph):\n",
        "        vertices = list(G.vertex_dict.keys())\n",
        "        d = {v: (len(G.adj_list_in[G.vertex_dict[v]]) + len(G.adj_list_out[G.vertex_dict[v]])) for v in vertices}\n",
        "        return d\n",
        "\n",
        "    \n",
        "def get_num_edges(G):\n",
        "    count = 0\n",
        "    for in_edges in G.adj_list_in:\n",
        "        count += len(in_edges)\n",
        "    return count\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reference\n",
        "`[1].` Akiba, T., Iwata, Y., & Yoshida, Y. (2013, June). Fast exact shortest-path distance queries on large networks by pruned landmark labeling. In Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data (pp. 349-360).\n",
        "\n",
        "`[2].` Cheng, J., & Yu, J. X. (2009, March). On-line exact shortest distance query processing. In Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology (pp. 481-492).\n",
        "\n",
        "`[3].` Cohen, E., Halperin, E., Kaplan, H., & Zwick, U. (2003). Reachability and distance queries via 2-hop labels. SIAM Journal on Computing, 32(5), 1338-1355."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "“Q1.ipynb”的副本",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
